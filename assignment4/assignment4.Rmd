---
title: "Assignment 4"
output: html_document
date: "2025-05-13"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Load Packages
```{r}
pacman::p_load(tidyverse, here, posterior, cmdstanr, brms, tidybayes, rstan, 
               ggplot2, dplyr, patchwork)
```

# EMPERICAL DATA
## Load Emperical Data and Clean it
Data used contains: 
- *The 'dangerous' category* (not 'nutrisious')
- *Condition 2* individuals (not condition 1 (dyads))
- *Session 1* danger: aliens with spots AND eyes on stalks (not sessions 2 and 3)
- *Non-test rows* 
```{r}
emp_data <- read.delim("data/AlienData.txt", sep = ",")
emp_data$subject <- as.factor(emp_data$subject)  # make subject categorical
emp_data <- emp_data[emp_data$session == 1 &     # incl only session 1
                       emp_data$condition == 2 & # incl only condition 2
                       emp_data$test == 0,]      # remove test rows
# remove columns not used
emp_data <- emp_data %>% 
  select(-c(condition, session, test, nutricious, RT, motivation, competence, communication, complement)) %>% 
  group_by(subject) %>% 
  mutate(performance = cumsum(correct) / seq_along(correct))
```

## Expand Features
Stimulus column contains the alien-file names. The features are indicated by a 0 or 1 in a set position: 
*1. eyes*: on stalks = 1, not on stalks = 0
*2. legs*: small = 1, big = 0
*3. spots*: spots = 1, no spots = 0
*4. arms*: up = 1, down = 0
*5. color*: green = 1, blue = 0
The five features are added as binary columns
```{r}
emp_data[,c("eyes", "legs", "spots", "arms", "color")] <- str_split_fixed(emp_data$stimulus, pattern = "", n = 6)[,1:5]
emp_data <- emp_data %>% 
  mutate_at(c("eyes", "legs", "spots", "arms", "color"), as.integer)
```

## Plot the Emperical Data
### Cumulative Scores and Performance for each Participant 
Calculate mean cumulative value per trial and plot it along each subjects
```{r}
mean_emp <- emp_data %>% 
  group_by(trial) %>% 
  summarise(mean_cum = mean(cumulative)/100, mean_perf = mean(performance))

p1 <- ggplot()+
  geom_line(data = emp_data, aes(group = subject, x = trial, y = cumulative/100), 
            color = "grey")+
  geom_line(data = mean_emp, aes(x = trial, y = mean_cum), color = "purple3")+
  annotate(geom="text", x= nrow(mean_emp)+4, 
           y= mean_emp$mean_cum[mean_emp$trial == nrow(mean_emp)], 
           label="Mean", color = "purple3", size = 3) +
  ggtitle("Emperical Data Cumulative Score")+
  labs(y = "cumulative")+
  theme_minimal()

p2 <- ggplot(emp_data)+
  geom_line(aes(x = trial, y = performance), color = "grey")+
  geom_line(data = mean_emp, aes(x = trial, y = mean_perf), color = "green4")+
  annotate(geom="text", x= nrow(mean_emp)+4, 
           y= mean_emp$mean_perf[mean_emp$trial == nrow(mean_emp)], 
           label="Mean", color = "green4", size = 3) +
  ggtitle("Emperical Data Performance")+
  theme_minimal()
p1/p2
ggsave(filename = "figs/emperical_data_performance.png")
```

### Percentage of Correct Categorisation per Stimuli
```{r}
emp_data_sum <- pivot_wider(
  emp_data[c("stimulus", "correct", "dangerous", "cycle")], names_from = correct,
  values_from = correct, values_fn = length, values_fill = 0)
colnames(emp_data_sum) <- c("stimuli", "danger", "cycle", "wrong", "correct")
emp_data_sum$stimuli <- str_split_fixed(emp_data_sum$stimuli, 
                                        pattern = ".jpg", n = 2)[,1]

emp_data_sum <- emp_data_sum %>% 
  group_by(cycle) %>% 
  arrange(desc(danger)) %>% 
  group_by(cycle, stimuli) %>% 
  mutate(n = (wrong+correct)) %>% 
  mutate(perc_corr = (correct/n)*100) %>% 
  mutate_at(c("stimuli", "cycle"), as.factor)
```

```{r}
ggplot(emp_data_sum) +
  geom_point(aes(x = cycle, y = stimuli,  size = perc_corr, fill = perc_corr), 
               alpha=0.7, shape = 21, position = position_jitter(width = 0.15)) + 
  scale_fill_viridis_c(breaks = c(25, 50, 75, 100), guide = "legend", name="% Correct")+ 
  scale_size_continuous(range = c(.5, 10),  name="% Correct", 
                        breaks = c(25, 50, 75, 100), guide = "legend")+
  theme_minimal()+ 
  facet_grid(row = "danger", scales = "free_y", space = "free_y", labeller = label_both)+
  theme(panel.grid = element_blank(), 
        panel.spacing = unit(1.5, "lines"))+ 
  coord_cartesian(clip = "off")
```

# FUNCTIONS 
## Experiment Function
The function implements the structure of the experiment, and returns a df with the order of the stimuli for a given number of cycles. It has the following parameters: 
*stimuli*: list of unique stimuli (the 32 alien-filenames)
*cycles*: the number of times the stimuli should be repeated (3 cycles)
*danger_fun*: how the 'danger' category is implemented (so far just the 'ADD' option)
*danger_features*: the features indicating danger
*danger_vals*: the values each of the danger features should have to be dangerous. 
The function returns a dataframe with nrows = number of stimuli * cycles. A stimuli column, a cycle column and a danger column. 
```{r}
experiment <- function(agent_id, w_key, c, stimuli, cycles, danger_fun = "ADD", 
                       danger_features, danger_vals){
  trials <- length(stimuli)*cycles
  n_stim <- length(stimuli)
  stim_df <- data.frame(w = rep(w_key, trials), c = rep(c, trials), 
                        agent_id = rep(agent_id, trials), trial = 1:trials, 
                        cycle = rep(NA, trials), stimuli = rep(NA, trials), 
                        danger = rep(NA, trials))
  for(cycle in 1:cycles){
    stim_order <- sample(stimuli, size = n_stim, replace = F)
    for(i in 1:n_stim){
      n_trial <- i+((cycle-1) *n_stim)
      stim_df[n_trial, "cycle"] <- cycle
      stim_df[n_trial , "stimuli"] <- stim_order[i]
    }
  } 
  stim_df[,c("eyes", "legs", "spots", "arms", "color")] <- str_split_fixed(
    stim_df$stimuli, pattern = "", n = 5)
  if(danger_fun == "ADD"){
    stim_df$danger <- ifelse(stim_df[danger_features[1]] == danger_vals[1] & 
                             stim_df[danger_features[2]] == danger_vals[2], 1, 0)[,1]
  }
  else{
    print("The danger function is not implemented in the experiment function")
  }
  stim_df <- stim_df %>% mutate_at(c("danger", "eyes", "legs", "spots", "arms", "color"), as.integer)
  return(stim_df)
}
```

## Softmax Function
```{r}
softmax <- function(vector){
  return(exp(vector)/sum(exp(vector)))
}
```

## General Context Model Functions
### Distance & Similarity
```{r}
distance <- function(vect1, vect2, w) {
  return(sum(w * abs(vect1 - vect2)))
}

similarity <- function(distance, c) {
  return(exp(-c * distance))
}
```

### Agent Functions 
- *w*       : Attention weight (attention to one parameter dimension, sums to 1)
- *c*       : Sensitivity parameter (determines how quickly similarity decreases with distance)
- *obs*     : Obervations (list of simuli, one for each trial)
- *cat_list*: List of 0/1 for each trial (1 = danger, 0 = not danger) 
```{r}
gcm_agent <- function(w, c, obs, cat_list){
  cat_probs <- c()     # list of probabilities of selecting '1' (danger) for each trial
  ntrials <- nrow(obs) # number of trials
  for (i in 1:ntrials){
    # for first trial and if the category hasn't been seen yet: 
    if (i == 1 || sum(cat_list[1:(i - 1)]) == 0 || sum(cat_list[1:(i - 1)]) == (i - 1)) {
      cat_probs <- c(cat_probs, 0.5) # random guess 
    }
    else {
      similarities <- c() # list of similarities between current simuli and all previous
      for (e in 1:(i - 1)) {
        dist <- distance(obs[i, ], obs[e, ], w)              # calculate distance
        similarities <- c(similarities, similarity(dist, c)) # caluclate similarity
      }
      # probability of categorising i as dangerous: 
      numerator <- mean(similarities[cat_list[1:(i - 1)] == 1])
      denominator <- mean(similarities[cat_list[1:(i - 1)] == 1]) + mean(
        similarities[cat_list[1:(i - 1)] == 0])
      cat_probs <- c(cat_probs, numerator / denominator)
    }
  }
  choices <- rbinom(ntrials, 1, cat_probs)
  return(choices)
}
```

# SIMULATION
## Simulate Agents
```{r}
#different weight dists
weights <- list("even" = softmax(rep(1, 5)), 
                "eyes_spots" = softmax(c(1.8, 1, 1.8, 1, 1)), 
                "color_arms" = softmax(c(1, 1, 1, 1.8, 1.8)))
c <- 1.5                # sensitivity paramater 
cycles <- 3             # number of times stimuli is repeated
n_agents <- 10          # number of agents to be simulated 
# define unique stimuli: 
stim <- unique(str_split_fixed(emp_data$stimulus, pattern = ".jpg", n = 2)[,1]) 
d_features <- c("eyes", "spots")
d_vals <- c(1, 1)

for (j in 1:length(weights)){
  w <- weights[[j]]
  for(i in 1:n_agents){
    # create exp data frame and unique stim order for given agent: 
    exp_df <- experiment(agent_id = i, w = names(weights)[j], c = c, 
                         stimuli = stim , cycles = cycles, danger_fun = "ADD",
                         danger_features = d_features, danger_vals = d_vals)
    # generate choices for the agent according to GCM: 
    exp_df$a_choices <- gcm_agent(
      w = w, c = c, obs = exp_df[c("eyes", "legs", "spots", "arms", "color")], 
      cat_list = exp_df$danger)
    # Define correct choices, cumulative scores and performance: 
    exp_df$correct <- ifelse(exp_df$a_choices == exp_df$danger, 1, 0) 
    exp_df$cumulative <- cumsum(ifelse(exp_df$correct == 1, 1, -1))   
    exp_df$performance <- cumsum(exp_df$correct) / seq_along(exp_df$correct)
    if (i == 1){
      sim_data <- exp_df
    }
    else{
      sim_data <- rbind(sim_data, exp_df)
    }
  }
  if (j == 1){
    sim_data_w <- sim_data
  }
  else{
    sim_data_w <- rbind(sim_data_w, sim_data)
  }
  cat("Finished simulating", n_agents, "agents with w of", w, "\n")
}
```

## Save in STAN-friendly Format
```{r}

```


## Plot Performance and Cumulative Score of Simulation
```{r}
mean_sim <- sim_data_w %>% 
  group_by(w, trial) %>%   
  summarise(mean_cum = mean(cumulative), mean_perf = mean(performance))

ggplot()+
  geom_line(data = sim_data_w, aes(x = trial, y = cumulative),color = "grey")+
  geom_line(data = mean_sim, aes(x = trial, y = mean_cum, color = w), show.legend = F)+
  scale_color_viridis_d()+
  ggtitle("Simulation Cumulative Score (c: 1)")+
  facet_wrap(~w, labeller = label_both)+
  theme_minimal()
ggsave(filename = "figs/sim_cumulative.png")

ggplot()+
  geom_line(data = sim_data_w, aes(x = trial, y = performance), color = "grey")+
  geom_line(data = mean_sim, aes(x = trial, y = mean_perf, color = w), show.legend = F)+
  scale_color_viridis_d()+
  ggtitle("Simulation Performance (c: 1)")+
  facet_wrap(~w, labeller = label_both)+
  theme_minimal()
ggsave(filename = "figs/sim_performance.png")
```

## Percentage of Correct Categorisation per Stimuli Plot 
```{r}
## calculate percent correct categorisations
sim_data_sum <- pivot_wider(sim_data_w[c("w", "stimuli", "correct", "danger", "cycle")], 
                            names_from = correct, values_from = correct, values_fn = length, 
                            values_fill = 0)
colnames(sim_data_sum) <- c("w", "stimuli", "danger", "cycle", "wrong", "correct")
sim_data_sum <- sim_data_sum %>% 
  group_by(w, cycle, stimuli) %>% 
  mutate(perc_corr = (correct/(wrong+correct))*100) %>% 
  mutate_at( "cycle", as.factor)
```

```{r}
ggplot(sim_data_sum) +
  geom_point(aes(x = cycle, y = stimuli,  size = perc_corr, fill = perc_corr), 
               alpha=0.7, shape = 21, position = position_jitter(width = 0.25)) + 
  scale_fill_viridis_c(breaks = c(30, 50, 70, 90), guide = "legend", name="% Correct")+ 
  scale_size_continuous(range = c(.1, 8),  name="% Correct", 
                        breaks = c(30, 50, 70, 90), guide = "legend")+
  theme_minimal()+ 
  facet_grid(row = vars(danger), col = vars(w), scales = "free_y", 
             space = "free_y", labeller = label_both)+
  theme(panel.grid = element_blank(), 
        panel.spacing = unit(1.5, "lines"))+ 
  coord_cartesian(clip = "off")
```





# STAN MODEL

```{r}

```


# FIT & CHECK STAN ON SIMULATED DATA 

## Fit the STAN Model (Simulated Data)
```{r}

```

## Model Quality Checks (Simulated Data)
```{r}

```


# FIT & CHECK STAN ON EMPERICAL DATA

## Fit the STAN Model (Emperical Data)
```{r}

```

## Model Quality Checks (Emperical Data)
```{r}

```







