---
title: "Assignment 4"
output: html_document
date: "2025-05-13"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Load Packages
```{r}
pacman::p_load(tidyverse, here, posterior, cmdstanr, brms, tidybayes, rstan, 
               ggplot2, dplyr, patchwork)
```

# EMPERICAL DATA
## Load Emperical Data and Clean it
Data used contains: 
- *The 'dangerous' category* (not 'nutrisious')
- *Condition 1* dyads (not condition 2)
- *Session 1* danger: aliens with spots AND eyes on stalks (not sessions 2 and 3)
- *Non-test rows* 
```{r}
emp_data <- read.delim("data/AlienData.txt", sep = ",")
emp_data$subject <- as.factor(emp_data$subject)  # make subject categorical
emp_data <- emp_data[emp_data$session == 1 &     # incl only session 1
                       emp_data$condition == 1 & # incl only condition 1
                       emp_data$test == 0,]      # remove test rows
# remove columns not used
emp_data <- emp_data %>% 
  select(-c(condition, session, test, nutricious, RT, motivation, 
            competence, communication, complement)) %>% 
  group_by(subject) %>% 
  mutate(performance = cumsum(correct) / seq_along(correct))
```

## Expand Features
Stimulus column contains the alien-file names. The features are indicated by a 0 or 1 in a set position: 
*1. eyes*: on stalks = 1, not on stalks = 0
*2. legs*: small = 1, big = 0
*3. spots*: spots = 1, no spots = 0
*4. arms*: up = 1, down = 0
*5. color*: green = 1, blue = 0
The five features are added as binary columns
```{r}
emp_data[,c("eyes", "legs", "spots", "arms", "color")] <- str_split_fixed(
  emp_data$stimulus, pattern = "", n = 6)[,1:5]
emp_data <- emp_data %>% 
  mutate_at(c("eyes", "legs", "spots", "arms", "color"), as.integer)
```

## Plot the Emperical Data
### Cumulative Scores and Performance for each Participant 
Calculate mean cumulative value per trial and plot it along each subjects
```{r}
mean_emp <- emp_data %>% 
  group_by(trial) %>% 
  summarise(mean_cum = mean(cumulative)/100, mean_perf = mean(performance))

p1 <- ggplot()+
  geom_line(data = emp_data, aes(group = subject, x = trial, y = cumulative/100), 
            color = "grey")+
  geom_line(data = mean_emp, aes(x = trial, y = mean_cum), color = "purple3")+
  annotate(geom="text", x= nrow(mean_emp)+4, 
           y= mean_emp$mean_cum[mean_emp$trial == nrow(mean_emp)], 
           label="Mean", color = "purple3", size = 3) +
  ggtitle("Emperical Data Cumulative Score")+
  labs(y = "cumulative")+
  theme_minimal()

p2 <- ggplot(emp_data)+
  geom_line(aes(x = trial, y = performance), color = "grey")+
  geom_line(data = mean_emp, aes(x = trial, y = mean_perf), color = "green4")+
  annotate(geom="text", x= nrow(mean_emp)+4, 
           y= mean_emp$mean_perf[mean_emp$trial == nrow(mean_emp)], 
           label="Mean", color = "green4", size = 3) +
  ggtitle("Emperical Data Performance")+
  theme_minimal()
p1/p2
ggsave(filename = "figs/emperical_data_performance.png")
```

### Percentage of Correct Categorisation per Stimuli
```{r}
emp_data_sum <- pivot_wider(
  emp_data[c("stimulus", "correct", "dangerous", "cycle")], 
  names_from = correct, values_from = correct, values_fn = length, values_fill = 0)

colnames(emp_data_sum) <- c("stimuli", "danger", "cycle", "wrong", "correct")
emp_data_sum$stimuli <- str_split_fixed(emp_data_sum$stimuli, 
                                        pattern = ".jpg", n = 2)[,1]
emp_data_sum <- emp_data_sum %>% 
  group_by(cycle) %>% 
  arrange(desc(danger)) %>% 
  group_by(cycle, stimuli) %>% 
  mutate(n = (wrong+correct)) %>% 
  mutate(perc_corr = (correct/n)*100) %>% 
  mutate_at(c("stimuli", "cycle"), as.factor)
```

```{r}
ggplot(emp_data_sum) +
  geom_point(aes(x = cycle, y = stimuli,  size = perc_corr, fill = perc_corr), 
               alpha=0.7, shape = 21, position = position_jitter(width = 0.15)) + 
  scale_fill_viridis_c(breaks = c(25, 50, 75, 100), guide = "legend", name="% Correct")+ 
  scale_size_continuous(range = c(.5, 10),  name="% Correct", 
                        breaks = c(25, 50, 75, 100), guide = "legend")+
  theme_minimal()+ 
  facet_grid(row = "danger", scales = "free_y", space = "free_y", labeller = label_both)+
  theme(panel.grid = element_blank(), 
        panel.spacing = unit(1.5, "lines"))+ 
  coord_cartesian(clip = "off")
```

# FUNCTIONS 
## Experiment Function
The function implements the structure of the experiment, and returns a df with the order of the stimuli for a given number of cycles. It has the following parameters: 
*agent_id*: the id for the given agent
*w_key*: some string indicating what weights are being used. 
*c*: The sensitivity scale used. 
*stimuli*: list of unique stimuli (the 32 alien-filenames)
*cycles*: the number of times the stimuli should be repeated (3 cycles)
*danger_fun*: how the 'danger' category is implemented (so far just the 'ADD' option)
*danger_features*: the features indicating danger
*danger_vals*: the values each of the danger features should have to be dangerous. 

The function returns a dataframe with nrows = number of stimuli * cycles. A stimuli column, a cycle column and a danger column. 
```{r}
experiment <- function(agent_id, w_key, c, stimuli, cycles, danger_fun = "ADD", 
                       danger_features, danger_vals){
  trials <- length(stimuli)*cycles
  n_stim <- length(stimuli)
  stim_df <- data.frame(w = rep(w_key, trials), c = rep(c, trials), 
                        agent_id = rep(agent_id, trials), trial = 1:trials, 
                        cycle = rep(NA, trials), stimuli = rep(NA, trials), 
                        danger = rep(NA, trials))
  for(cycle in 1:cycles){
    stim_order <- sample(stimuli, size = n_stim, replace = F)
    for(i in 1:n_stim){
      n_trial <- i+((cycle-1) *n_stim)
      stim_df[n_trial, "cycle"] <- cycle
      stim_df[n_trial , "stimuli"] <- stim_order[i]
    }
  } 
  stim_df[,c("eyes", "legs", "spots", "arms", "color")] <- str_split_fixed(
    stim_df$stimuli, pattern = "", n = 5)
  if(danger_fun == "ADD"){
    stim_df$danger <- ifelse(stim_df[danger_features[1]] == danger_vals[1] & 
                             stim_df[danger_features[2]] == danger_vals[2], 1, 0)[,1]
  }
  else{
    print("The danger function is not implemented in the experiment function")
  }
  stim_df <- stim_df %>% mutate_at(c("danger", "eyes", "legs", "spots", "arms", "color"), as.integer)
  return(stim_df)
}
```

## Softmax Function
Softmax function to generate weights for the features that sum to 1 
```{r}
softmax <- function(vector){
  return(exp(vector)/sum(exp(vector)))
}
```

## General Context Model Functions
### Distance & Similarity
```{r}
distance <- function(vect1, vect2, w) {
  return(sum(w * abs(vect1 - vect2)))
}

similarity <- function(distance, c) {
  return(exp(-c * distance))
}

```

### Agent Functions 
- *w*       : Attention weight (attention to parameter dimensions, sums to 1)
- *c*       : Sensitivity parameter (determines how quickly similarity decreases with distance)
- *obs*     : Obervations (list of simuli, one for each trial)
- *cat_list*: List of 0/1 for each trial (1 = danger, 0 = not danger) 
```{r}
gcm_agent <- function(w, c, obs, cat_list){
  cat_probs <- c()     # list of probabilities of selecting '1' (danger) for each trial
  ntrials <- nrow(obs) # number of trials
  for (i in 1:ntrials){
    # for first trial and if the category hasn't been seen yet: 
    if (i == 1 || sum(cat_list[1:(i - 1)]) == 0 || sum(cat_list[1:(i - 1)]) == (i - 1)) {
      cat_probs <- c(cat_probs, 0.5) # random guess 
    }
    else {
      similarities <- c() # list of similarities between current simuli and all previous
      for (e in 1:(i - 1)) {
        dist <- distance(obs[i, ], obs[e, ], w)              # calculate distance
        similarities <- c(similarities, similarity(dist, c)) # caluclate similarity
      }
      # probability of categorising i as dangerous: 
      numerator <- mean(similarities[cat_list[1:(i - 1)] == 1])
      denominator <- mean(similarities[cat_list[1:(i - 1)] == 1]) + mean(
        similarities[cat_list[1:(i - 1)] == 0])
      cat_probs <- c(cat_probs, numerator / denominator)
    }
  }
  choices <- rbinom(ntrials, 1, cat_probs)
  return(choices)
}
```

# SIMULATION
## Simulate Agents
```{r}
#different weight dists
weights <- list("even" = softmax(rep(1, 5)),                 # 0.2 0.2 0.2 0.2 0.2
                "eyes_spots" = softmax(c(1.8, 1, 1.8, 1, 1)),# 0.299 0.134 0.299 0.134 0.134
                "color_arms" = softmax(c(1, 1, 1, 1.8, 1.8)))# 0.134 0.134 0.134 0.299 0.299
c <- 1.5                # sensitivity paramater 
cycles <- 3             # number of times stimuli is repeated

n_agents <- 4*length(weights)  # number of agents to be simulated: 10 with each of the weight dists 

# define unique stimuli: 
stim <- unique(str_split_fixed(emp_data$stimulus, pattern = ".jpg", n = 2)[,1]) 
d_features <- c("eyes", "spots") #the features that with d_vals indicate danger
d_vals <- c(1, 1)                #the values of d_features for them to indicate danger


for (j in 1:length(weights)){
  w <- weights[[j]] # vector of weights for each feature
  for(i in (j*10-9):(j*10)){ #go through ten agents for each weight vect (1: 1-10, 2: 11-20, 3: 21-30)
    # create exp data frame and unique stim order for given agent: 
    exp_df <- experiment(agent_id = i, w = names(weights)[j], c = c, 
                         stimuli = stim , cycles = cycles, danger_fun = "ADD",
                         danger_features = d_features, danger_vals = d_vals)
    # generate choices for the agent according to GCM: 
    exp_df$a_choices <- gcm_agent(
      w = w, c = c, obs = exp_df[c("eyes", "legs", "spots", "arms", "color")], 
      cat_list = exp_df$danger)
    # Define correct choices, cumulative scores and performance: 
    exp_df$correct <- ifelse(exp_df$a_choices == exp_df$danger, 1, 0) 
    exp_df$cumulative <- cumsum(ifelse(exp_df$correct == 1, 1, -1))   
    exp_df$performance <- cumsum(exp_df$correct) / seq_along(exp_df$correct)
    if (i == 1){
      sim_data <- exp_df
    }
    else{
      sim_data <- rbind(sim_data, exp_df)
    }
  }
  if (j == 1){
    sim_data_w <- sim_data
  }
  else{
    sim_data_w <- rbind(sim_data_w, sim_data)
  }
  cat("Finished simulating", n_agents, "agents with w of", w, "\n")
}
```

## Plot Performance and Cumulative Score of Simulation
```{r}
mean_sim <- sim_data_w %>% 
  group_by(w, trial) %>%   
  summarise(mean_cum = mean(cumulative), mean_perf = mean(performance))

ggplot()+
  geom_line(data = sim_data_w, aes(x = trial, y = cumulative),color = "grey")+
  geom_line(data = mean_sim, aes(x = trial, y = mean_cum, color = w), show.legend = F)+
  scale_color_viridis_d()+
  ggtitle("Simulation Cumulative Score (c: 1)")+
  facet_wrap(~w, labeller = label_both)+
  theme_minimal()
ggsave(filename = "figs/sim_cumulative.png")

ggplot()+
  geom_line(data = sim_data_w, aes(x = trial, y = performance), color = "grey")+
  geom_line(data = mean_sim, aes(x = trial, y = mean_perf, color = w), show.legend = F)+
  scale_color_viridis_d()+
  ggtitle("Simulation Performance (c: 1)")+
  facet_wrap(~w, labeller = label_both)+
  theme_minimal()
ggsave(filename = "figs/sim_performance.png")
```

## Percentage of Correct Categorisation per Stimuli Plot 
```{r}
## calculate percent correct categorisations
sim_data_sum <- pivot_wider(sim_data_w[c("w", "stimuli", "correct", "danger", "cycle")], 
                            names_from = correct, values_from = correct, values_fn = length, 
                            values_fill = 0)
colnames(sim_data_sum) <- c("w", "stimuli", "danger", "cycle", "wrong", "correct")
sim_data_sum <- sim_data_sum %>% 
  group_by(w, cycle, stimuli) %>% 
  mutate(perc_corr = (correct/(wrong+correct))*100) %>% 
  mutate_at( "cycle", as.factor)
```

```{r}
ggplot(sim_data_sum) +
  geom_point(aes(x = cycle, y = stimuli,  size = perc_corr, fill = perc_corr), 
               alpha=0.7, shape = 21, position = position_jitter(width = 0.25)) + 
  scale_fill_viridis_c(breaks = c(30, 50, 70, 90), guide = "legend", name="% Correct")+ 
  scale_size_continuous(range = c(.1, 8),  name="% Correct", 
                        breaks = c(30, 50, 70, 90), guide = "legend")+
  theme_minimal()+ 
  facet_grid(row = vars(danger), col = vars(w), scales = "free_y", 
             space = "free_y", labeller = label_both)+
  theme(panel.grid = element_blank(), 
        panel.spacing = unit(1.5, "lines"))+ 
  coord_cartesian(clip = "off")
```



## Save in STAN-friendly Format
```{r}
# unique stimuli and category df with stimuli ids : 
stim_df <- unique(sim_data_w[c("danger", "eyes", "legs", "spots", "arms", "color")])
stim_df$s_id <- seq(1:nrow(stim_df))
#combine stim_df with ids and simulated df 
sim_data_w <- left_join(sim_data_w, stim_df)


sim_data <- list(
  total_N = nrow(sim_data_w),                    # total number of observations (all agents)
  nagents = length(unique(sim_data_w$agent_id)), # number of individual agents
  agent_id = sim_data_w$agent_id,                # agent id for each observation
  n_trials = 96,                                 # number of trials for each agent 
  nfeatures = 5,                                 # number of features for stimuli
  nstim = 32,                                    # number of unique stimuli
  stimuli = as.matrix(stim_df[c(
  "eyes", "legs", "spots", "arms", "color")]),   # matrix of [nstim, nfeatures] indices: s_id
  cat_danger = stim_df$danger,                   # array of cats with indices as s_id
  obs = as.matrix(pivot_wider(unique(            # matrix[nagents, ntrials] with obs
    sim_data_w[c("s_id", "agent_id", "trial")]), 
            names_from = trial, values_from = s_id)[-1], 
    dimnames = list(unique(sim_data_w$agent_id), 
                    unique(sim_data_w$trial))),
  b = 0.5,                                       # bias for selecting one cat over the other
  choice = as.matrix(pivot_wider(unique(sim_data_w[c("danger", "agent_id", "trial")]), 
            names_from = trial, values_from = danger)[-1], 
    dimnames = list(unique(sim_data_w$agent_id), 
                    unique(sim_data_w$trial))),
  
  #choice = sim_data_w$a_choices                  # array of choice for each trial 
  
  w_prior_values = c(1, 1, 1, 1, 1),
  c_prior_values = c(0, 1)
)




```


# STAN MODEL

```{r}
stan_gcm <- "
data{
  int<lower=1> total_N; 
  int<lower=1> nagents;
  int<lower=1> agent_id;
  int<lower=1> n_trials;
  int<lower=1> nfeatures;
  int<lower=1> nstim;
  
  real<lower=0, upper=1> b;
  
  array[nstim, nfeatures] int<lower=0, upper=1> stimuli; 
  array[nagents, n_trials] int<lower=1, upper=32> obs;
  array[nstim] int<lower=0, upper=1> cat_danger;
  array[nagents, n_trials] int<lower=0, upper=1> choice;
  
  //array[total_N]int<lower=0, upper=1> choice; 
  
  // priors
  array[nfeatures] real w_prior_values;  // concentration parameters for dirichlet distribution <lower=1>
  array[2] real c_prior_values;     // mean and variance for logit-normal distribution
}

parameters{
  row_stochastic_matrix[nagents, nfeatures] w;
  array[nagents] real logit_c;

}

transformed parameters{

  // parameter c
  array[nagents] real<lower=0, upper=2> c = inv_logit(logit_c)*2;
  
  // Parameter r (probability of response = 1 ) 
  array[nagents, n_trials] real<lower=0.0001, upper=0.9999> r;
  array[nagents, n_trials] real rr; 


  for (a in 1:nagents){
  
  	for (i in 1:n_trials){
  	
  		array[(i-1)] real exemp_similarities; 
  		
  		for (e in 1:(i-1)){ // loop through previous aliens
  		
  			array[nfeatures] real tmp_distance;
  			
  			for (j in 1:nfeatures){ // loop through each feature in alien e
  			
  				tmp_distance[j] = w[a,j]*abs(stimuli[obs[a, e], j] -  stimuli[obs[a, i], j] );
  			}
  			
  			exemp_similarities[e] = exp(-c * sum(tmp_distance));
  		
  		}
  		
      if (i == 1 || sum(cat_danger[obs[a, (1:i-1)]]) == 0 || sum(cat_danger[obs[a, (1:i-1)]]) == (i-1)){
        r[i] = 0.5;
      }
      else{
        
        // calculate similarity
        
        array[2] real similarities; // summed similarities for each cat
        
        similarities[1] = sum(cat_danger[obs[a, (1:i-1)]]*exemp_similarities);
        similarities[2] = sum(abs(cat_danger[obs[a, (1:i-1)]]-1)*exemp_similarities);
        
        // calculate r[a, i]
        
        rr[a, i] = (b*similarities[1]) / (b*similarities[1] + (1-b)*similarities[2]);

        // to make the sampling work
        
        if (rr[a, i] > 0.9999){
          r[a, i] = 0.9999;
        } else if (rr[a, i] < 0.0001){
            r[a, i] = 0.0001;
        } else if (rr[a, i] > 0.0001 && rr[a, i] < 0.9999){
            r[a, i] = rr[a, i];
        } else{
            r[a, i] = 0.5;
        }
      }
  	}
  }
}

model {
  // Priors
  
  for (a in 1:nagents){
    target += dirichlet_lpdf(w[a,] | w_prior_values);
    target += normal_lpdf(logit_c[a] | c_prior_values[1], c_prior_values[2]);
  }
    
  // Decision Data
  for (a in 1:nagents){
    for (i in 1:n_trials){
      target += bernoulli_lpmf(choice[a, i] | r[a, i]);
    }
  }
}

"
# Write the model to a file
write_stan_file(
  stan_gcm,
  dir = "stan/",
  basename = "gcm.stan"
)

```


# FIT & CHECK STAN ON SIMULATED DATA 

## Fit the STAN Model (Simulated Data)
```{r}

file_gcm <- file.path("stan/gcm.stan")
mod_gcm <- cmdstan_model(file_gcm, 
                            cpp_options = list(stan_threads = TRUE))

samples_gcm <- mod_gcm$sample(
  data = data_simple,
  seed = 120,
  refresh = 500,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 1000,
  iter_sampling = 2000,
  max_treedepth = 20,
  adapt_delta = 0.99
)
simple_sum <- samples_simple$summary()
draws_df_simple <- as_draws_df(samples_simple$draws())

```

## Model Quality Checks (Simulated Data)
```{r}

```


# FIT & CHECK STAN ON EMPERICAL DATA

## Fit the STAN Model (Emperical Data)
```{r}

```

## Model Quality Checks (Emperical Data)
```{r}

```







