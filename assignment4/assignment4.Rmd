---
title: "Assignment 4"
output: html_document
date: "2025-05-13"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Load Packages
```{r}
pacman::p_load(tidyverse, here, posterior, cmdstanr, brms, tidybayes, rstan, 
               ggplot2, dplyr, patchwork)
```

# EMPIRICAL DATA
## Load Empirical Data and Clean it
Data used contains: 
- *The 'dangerous' category* (not 'nutrisious')
- *Condition 1* dyads (not condition 2)
- *Session 1* danger: aliens with spots AND eyes on stalks (not sessions 2 and 3)
- *Non-test rows* 
```{r}
emp_data <- read.delim("data/AlienData.txt", sep = ",")
emp_data$subject <- as.factor(emp_data$subject)  # make subject categorical
emp_data <- emp_data[emp_data$session == 1 &     # incl only session 1
                       emp_data$condition == 1 & # incl only condition 1
                       emp_data$test == 0,]      # remove test rows
# remove columns not used
emp_data <- emp_data %>% 
  select(-c(condition, session, test, nutricious, RT, motivation, # remove none needed columns
            competence, communication, complement)) %>% 
  group_by(subject) %>%                                           # group the data frame by subjects
  mutate(performance = cumsum(correct) / seq_along(correct))      # create a performance column 
```

## Expand Features
Stimulus column contains the alien-file names. The features are indicated by a 0 or 1 in a set position: 
*1. eyes*: on stalks = 1, not on stalks = 0
*2. legs*: small = 1, big = 0
*3. spots*: spots = 1, no spots = 0
*4. arms*: up = 1, down = 0
*5. color*: green = 1, blue = 0
The five features are added as binary columns
```{r}
emp_data[,c("eyes", "legs", "spots", "arms", "color")] <- str_split_fixed(
  emp_data$stimulus, pattern = "", n = 6)[,1:5]
emp_data <- emp_data %>% 
  mutate_at(c("eyes", "legs", "spots", "arms", "color"), as.integer)
```

## Plot the Empirical Data
### Cumulative Scores and Performance for each Participant 
Calculate mean cumulative value per trial and plot it along each subjects
```{r}
# Calculate mean cumulative and performance for each trial
mean_emp <- emp_data %>% 
  group_by(trial) %>% 
  summarise(mean_cum = mean(cumulative)/100, mean_perf = mean(performance))
# Plot the cumulative scores
p1 <- ggplot()+
  geom_line(data = emp_data, aes(group = subject, x = trial, y = cumulative/100), 
            color = "grey")+
  geom_line(data = mean_emp, aes(x = trial, y = mean_cum), color = "purple3")+
  annotate(geom="text", x= nrow(mean_emp)+4, 
           y= mean_emp$mean_cum[mean_emp$trial == nrow(mean_emp)], 
           label="Mean", color = "purple3", size = 3) +
  ggtitle("Empirical Data Cumulative Score")+
  labs(y = "cumulative")+
  theme_minimal()
# Plot the performance 
p2 <- ggplot(emp_data)+
  geom_line(aes(x = trial, y = performance), color = "grey")+
  geom_line(data = mean_emp, aes(x = trial, y = mean_perf), color = "green4")+
  annotate(geom="text", x= nrow(mean_emp)+4, 
           y= mean_emp$mean_perf[mean_emp$trial == nrow(mean_emp)], 
           label="Mean", color = "green4", size = 3) +
  ggtitle("Empirical Data Performance")+
  theme_minimal()
p1/p2
ggsave(filename = "figs/empirical_data_performance.png") #save in figs folder
```

### Percentage of Correct Categorisation per Stimuli
```{r}
# Calculate summary stats for each stimuli 
emp_data_sum <- pivot_wider(
  emp_data[c("stimulus", "correct", "dangerous", "cycle")], 
  names_from = correct, values_from = correct, values_fn = length, values_fill = 0)
colnames(emp_data_sum) <- c("stimuli", "danger", "cycle", "wrong", "correct")
emp_data_sum$stimuli <- str_split_fixed(emp_data_sum$stimuli, 
                                        pattern = ".jpg", n = 2)[,1]
emp_data_sum <- emp_data_sum %>% 
  group_by(cycle) %>% 
  arrange(desc(danger)) %>% 
  group_by(cycle, stimuli) %>% 
  mutate(n = (wrong+correct)) %>% 
  mutate(perc_corr = (correct/n)*100) %>% 
  mutate_at(c("stimuli", "cycle"), as.factor)
# Plot it
ggplot(emp_data_sum) +
  geom_point(aes(x = cycle, y = stimuli,  size = perc_corr, fill = perc_corr), 
               alpha=0.7, shape = 21, position = position_jitter(width = 0.15)) + 
  scale_fill_viridis_c(breaks = c(25, 50, 75, 100), guide = "legend", name="% Correct")+ 
  scale_size_continuous(range = c(.5, 10),  name="% Correct", 
                        breaks = c(25, 50, 75, 100), guide = "legend")+
  theme_minimal()+ 
  facet_grid(row = "danger", scales = "free_y", space = "free_y", labeller = label_both)+
  theme(panel.grid = element_blank(), panel.spacing = unit(1.5, "lines"))+ 
  coord_cartesian(clip = "off")
```


# FUNCTIONS 
## Experiment Function
The function implements the structure of the experiment, and returns a df with the order of the stimuli for a given number of cycles. It has the following parameters: 
*agent_id*: the id for the given agent
*w_key*: some string indicating what weights are being used. 
*c*: The sensitivity scale used. 
*stimuli*: list of unique stimuli (the 32 alien-filenames)
*cycles*: the number of times the stimuli should be repeated (3 cycles)
*danger_fun*: how the 'danger' category is implemented (so far just the 'ADD' option)
*danger_features*: the features indicating danger
*danger_vals*: the values each of the danger features should have to be dangerous. 

The function returns a dataframe with nrows = number of stimuli * cycles. A stimuli column, a cycle column and a danger column. 
```{r}
experiment <- function(agent_id, w_key, c, stimuli, cycles, danger_fun = "ADD", 
                       danger_features, danger_vals){
  trials <- length(stimuli)*cycles
  n_stim <- length(stimuli)
  stim_df <- data.frame(w = rep(w_key, trials), c = rep(c, trials), 
                        agent_id = rep(agent_id, trials), trial = 1:trials, 
                        cycle = rep(NA, trials), stimuli = rep(NA, trials), 
                        danger = rep(NA, trials))
  for(cycle in 1:cycles){
    stim_order <- sample(stimuli, size = n_stim, replace = F)
    for(i in 1:n_stim){
      n_trial <- i+((cycle-1) *n_stim)
      stim_df[n_trial, "cycle"] <- cycle
      stim_df[n_trial , "stimuli"] <- stim_order[i]
    }
  } 
  stim_df[,c("eyes", "legs", "spots", "arms", "color")] <- str_split_fixed(
    stim_df$stimuli, pattern = "", n = 5)
  if(danger_fun == "ADD"){
    stim_df$danger <- ifelse(stim_df[danger_features[1]] == danger_vals[1] & 
                             stim_df[danger_features[2]] == danger_vals[2], 1, 0)[,1]
  }
  else{
    print("The danger function is not implemented in the experiment function")
  }
  stim_df <- stim_df %>% mutate_at(c("danger", "eyes", "legs", "spots", "arms", "color"), as.integer)
  return(stim_df)
}
```

## Softmax Function
Softmax function to generate weights for the features that sum to 1 
```{r}
softmax <- function(vector){
  return(exp(vector)/sum(exp(vector)))
}
```

## General Context Model Functions
### Distance & Similarity
```{r}
distance <- function(vect1, vect2, w) {
  return(sum(w * abs(vect1 - vect2)))
}

similarity <- function(distance, c) {
  return(exp(-c * distance))
}

```

### Agent Functions 
- *w*       : Attention weight (attention to parameter dimensions, sums to 1)
- *c*       : Sensitivity parameter (determines how quickly similarity decreases with distance)
- *obs*     : Obervations (list of simuli, one for each trial)
- *cat_list*: List of 0/1 for each trial (1 = danger, 0 = not danger) 
```{r}
gcm_agent <- function(w, c, obs, cat_list){
  cat_probs <- c()     # list of probabilities of selecting '1' (danger) for each trial
  ntrials <- nrow(obs) # number of trials
  for (i in 1:ntrials){
    # for first trial and if the category hasn't been seen yet: 
    if (i == 1 || sum(cat_list[1:(i - 1)]) == 0 || sum(cat_list[1:(i - 1)]) == (i - 1)) {
      cat_probs <- c(cat_probs, 0.5) # random guess 
    }
    else {
      similarities <- c() # list of similarities between current simuli and all previous
      for (e in 1:(i - 1)) {
        dist <- distance(obs[i, ], obs[e, ], w)              # calculate distance
        similarities <- c(similarities, similarity(dist, c)) # caluclate similarity
      }
      # probability of categorising i as dangerous: 
      numerator <- mean(similarities[cat_list[1:(i - 1)] == 1])
      denominator <- mean(similarities[cat_list[1:(i - 1)] == 1]) + mean(
        similarities[cat_list[1:(i - 1)] == 0])
      cat_probs <- c(cat_probs, numerator / denominator)
    }
  }
  choices <- rbinom(ntrials, 1, cat_probs)
  return(choices)
}
```

# SIMULATION
## Simulate Agents
```{r}
# Define three sets of weights for the features to test
weights <- list("even" = softmax(rep(1, 5)),                 # 0.2 0.2 0.2 0.2 0.2
                "eyes_spots" = softmax(c(1.8, 1, 1.8, 1, 1)),# 0.299 0.134 0.299 0.134 0.134
                "color_arms" = softmax(c(1, 1, 1, 1.8, 1.8)))# 0.134 0.134 0.134 0.299 0.299

c <- 1.5                           # sensitivity parameter (same for all agents)
cycles <- 3                        # number of times stimuli is repeated
n_subA <- 10                       # number of agents per weight dists 
n_agents <- n_subA*length(weights) # total number of agents to be simulated: 10 with each of the weight dists 

stim <- unique(str_split_fixed(emp_data$stimulus, pattern = ".jpg", n = 2)[,1]) # define unique stimuli

d_features <- c("eyes", "spots") # the features that with d_vals indicate danger
d_vals <- c(1, 1)                # the values of d_features for them to indicate danger

# Simulate n_agents with the given parameters: 

for (j in 1:length(weights)){
  w <- weights[[j]] # vector of weights for each feature
  for(i in (j*n_subA-(n_subA-1)):(j*n_subA)){ #go through ten agents for each weight vect (1: 1-10, 2: 11-20, 3: 21-30)
    # create exp data frame and unique stim order for given agent: 
    exp_df <- experiment(agent_id = i, w = names(weights)[j], c = c, 
                         stimuli = stim , cycles = cycles, danger_fun = "ADD",
                         danger_features = d_features, danger_vals = d_vals)
    # generate choices for the agent according to GCM: 
    exp_df$a_choices <- gcm_agent(
      w = w, c = c, obs = exp_df[c("eyes", "legs", "spots", "arms", "color")], 
      cat_list = exp_df$danger)
    # Define correct choices, cumulative scores and performance: 
    exp_df$correct <- ifelse(exp_df$a_choices == exp_df$danger, 1, 0) 
    exp_df$cumulative <- cumsum(ifelse(exp_df$correct == 1, 1, -1))   
    exp_df$performance <- cumsum(exp_df$correct) / seq_along(exp_df$correct)
    if (i == 1){
      sim_data <- exp_df
    }
    else{
      sim_data <- rbind(sim_data, exp_df)
    }
  }
  cat("Finished simulating", n_agents/length(weights), "agents with w of", w, "\n")
}
```
## Plot Agents 

### Plot Performance and Cumulative Score of Simulation
```{r}
mean_sim <- sim_data %>% 
  group_by(w, trial) %>%   
  summarise(mean_cum = mean(cumulative), mean_perf = mean(performance))

ggplot()+
  geom_line(data = sim_data, aes(x = trial, y = cumulative),color = "grey")+
  geom_line(data = mean_sim, aes(x = trial, y = mean_cum, color = w), show.legend = F)+
  scale_color_viridis_d()+
  ggtitle("Simulation Cumulative Score (c: 1.5)")+
  facet_wrap(~w, labeller = label_both)+
  theme_minimal()
ggsave(filename = "figs/sim_cumulative.png")

ggplot()+
  geom_line(data = sim_data, aes(x = trial, y = performance), color = "grey")+
  geom_line(data = mean_sim, aes(x = trial, y = mean_perf, color = w), show.legend = F)+
  scale_color_viridis_d()+
  ggtitle("Simulation Performance (c: 1.5)")+
  facet_wrap(~w, labeller = label_both)+
  theme_minimal()
ggsave(filename = "figs/sim_performance.png")
```

### Percentage of Correct Categorisation per Stimuli Plot 
```{r}
## calculate percent correct categorisations
sim_data_sum <- pivot_wider(sim_data[c("w", "stimuli", "correct", "danger", "cycle")], 
                            names_from = correct, values_from = correct, values_fn = length, 
                            values_fill = 0)
colnames(sim_data_sum) <- c("w", "stimuli", "danger", "cycle", "wrong", "correct")
sim_data_sum <- sim_data_sum %>% 
  group_by(w, cycle, stimuli) %>% 
  mutate(perc_corr = (correct/(wrong+correct))*100) %>% 
  mutate_at( "cycle", as.factor)

ggplot(sim_data_sum) +
  geom_point(aes(x = cycle, y = stimuli,  size = perc_corr, fill = perc_corr), 
               alpha=0.7, shape = 21, position = position_jitter(width = 0.25)) + 
  scale_fill_viridis_c(breaks = c(30, 50, 70, 90), guide = "legend", name="% Correct")+ 
  scale_size_continuous(range = c(.1, 8),  name="% Correct", 
                        breaks = c(30, 50, 70, 90), guide = "legend")+
  theme_minimal()+ 
  facet_grid(row = vars(danger), col = vars(w), scales = "free_y", 
             space = "free_y", labeller = label_both)+
  theme(panel.grid = element_blank(), 
        panel.spacing = unit(1.5, "lines"))+ 
  coord_cartesian(clip = "off")
```





## Save in STAN-friendly Format
```{r}
# unique stimuli and category df with stimuli ids : 
stim_df <- unique(sim_data[c("danger", "eyes", "legs", "spots", "arms", "color")])
stim_df$s_id <- seq(1:nrow(stim_df))
sim_data <- left_join(sim_data, stim_df, #combine stim_df with ids and simulated df 
                      by = join_by("danger", "eyes", "legs", "spots", "arms", "color")) 

# observation matrix [nagents, ntrials] each value is the id for the observed stimuli
obs <- as.matrix(pivot_wider(sim_data[c("s_id", "agent_id", "trial")],
                             names_from = trial, values_from = s_id)[-1])
# choice matrix [nagents, ntrials] each value is the category assigned to the observed stimuli
choice <- as.matrix(pivot_wider(sim_data[c("a_choices", "agent_id", "trial")],
                             names_from = trial, values_from = a_choices)[-1])
# stimuli matrix [nstim, nfeatures] 
stimuli <- as.matrix(stim_df[c("eyes", "legs", "spots", "arms", "color")])

sim_data_ls <- list(
  nagents = n_agents,                # number of individual agents
  n_trials = 96,                     # number of trials for each agent 
  nfeatures = 5,                     # number of features for stimuli
  nstim = 32,                        # number of unique stimuli
  b = 0.5,                           # bias for selecting one cat over the other
  stimuli = stimuli,                 # matrix of [nstim, nfeatures] indices: s_id
  obs = obs,                         # matrix[nagents, ntrials] with obs
  cat_danger = stim_df$danger,       # array of cats with indices as s_id
  choice = choice,                   # matrix with choices [nagents, ntrials]
  w_prior_values = c(1, 1, 1, 1, 1), # priors for w
  c_prior_values = c(0, 1)           # priors for c
)

```


# STAN MODEL

```{r}
stan_gcm <- "
data{
  int<lower=1> nagents;                                   // number of agents
  int<lower=1> n_trials;                                  // number of trials 
  int<lower=1> nfeatures;                                 // number of features in each stimuli
  int<lower=1> nstim;                                     // number of unique stimuli
  real<lower=0, upper=1> b;                               // bias for selecting cat 'danger' (1)
  array[nstim, nfeatures] int<lower=0, upper=1> stimuli;  // features of each stimuli
  array[nagents, n_trials] int<lower=1, upper=32> obs;    // observations (s_id) for each agent+trial
  vector<lower=0, upper=1>[nstim] cat_danger;             // vector of categories for each unique stimuli
  array[nagents, n_trials] int<lower=0, upper=1> choice;  // agent-choice on each trial 
  
  // priors
  vector[nfeatures] w_prior_values;                       // priors for param w
  array[2] real c_prior_values;                           // mean and sd for logit-normal dist (param c)
}
parameters{
  row_stochastic_matrix[nagents, nfeatures] w;            // w param (each row is a simplex)
  vector[nagents] logit_c;                                // c param for each agent
}

transformed parameters{

  // Parameter c: inverse logit transformed 
  vector <lower=0, upper=2>[nagents] c = inv_logit(logit_c)*2;
  
  // Parameter r (probability of response = 1 ) 
  array[nagents, n_trials] real<lower=0.0001, upper=0.9999> r;
  array[nagents, n_trials] real rr; 

  for (a in 1:nagents){                     // Loop through each agent 
  	for (i in 1:n_trials){                  // Loop through each trial
  	
  		vector[(i-1)]  exemp_similarities;    // Vector of similarities between current obs and previous obs
  		
  		for (e in 1:(i-1)){                   // Loop through previous aliens
  			array[nfeatures] real tmp_distance; // Array of distances for each feature for previous alien e
  			
  			for (j in 1:nfeatures){             // Loop through each feature in alien e and calculate distances
  			  tmp_distance[j] = w[a,j]*abs(stimuli[obs[a, e], j] -  stimuli[obs[a, i], j] );
  			}
  			
  			// Calculate similarity between current alien and alien e:
  			exemp_similarities[e] = exp(-c[a] * sum(tmp_distance));
  		}
  		
  	  // If first trial or category is new, make r random: 	
      if (i == 1 || sum(cat_danger[obs[a, 1:(i-1)]]) == 0 || sum(cat_danger[obs[a, 1:(i-1)]]) == (i-1)){
        r[a, i] = 0.5;
      }
      
      // Otherwise calculate summed similarities (per category):
      else{
        array[2] real similarities; 
        
        vector[(i-1)] ind_danger = cat_danger[obs[a, 1:(i-1)]];      // vector of inds of dangerous stim
        vector[(i-1)] ind_safe = abs(cat_danger[obs[a, 1:(i-1)]]-1); // vector of inds of safe stim

        
        similarities[1] = sum(ind_danger.*exemp_similarities);       // sum of cat = 1
        similarities[2] = sum(ind_safe.*exemp_similarities);         // sum of cat = 0

        // Calculate probability of choosing 1:
        rr[a, i] = (b*similarities[1]) / (b*similarities[1] + (1-b)*similarities[2]);

        // (make sampling work)
        if (rr[a, i] > 0.9999){
          r[a, i] = 0.9999;
        } else if (rr[a, i] < 0.0001){
            r[a, i] = 0.0001;
        } else if (rr[a, i] > 0.0001 && rr[a, i] < 0.9999){
            r[a, i] = rr[a, i];
        } else{
            r[a, i] = 0.5;
        }
      }
  	}
  }
}

model {
  // Priors
  for (a in 1:nagents){
    target += dirichlet_lpdf(w[a,] | w_prior_values);
    target += normal_lpdf(logit_c[a] | c_prior_values[1], c_prior_values[2]);
  }
  // Liklihood
  
  for (a in 1:nagents){
    target += bernoulli_lpmf(choice[a, ] | r[a, ]);
  }
}

"
# Write the model to a file
write_stan_file(
  stan_gcm,
  dir = "stan/",
  basename = "gcm.stan"
)

```


# FIT & CHECK STAN ON SIMULATED DATA 

## Fit the STAN Model (Simulated Data)
```{r}
file_gcm <- file.path("stan/gcm.stan")
mod_gcm <- cmdstan_model(file_gcm, 
                         cpp_options = list(stan_threads = TRUE))

samples_gcm <- mod_gcm$sample(
  data = sim_data_ls,
  seed = 10,
  refresh = 100,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 1,
  iter_warmup = 500,
  iter_sampling = 1000,
  max_treedepth = 20,
  adapt_delta = 0.99
)


gcm_sum <- samples_gcm$summary()
draws_df_gcm <- as_draws_df(samples_gcm$draws())
```

## Save Data
```{r}
## Save gcm_sum and draws_df_gcm as RData
save(gcm_sum, draws_df_gcm, sim_data_ls, file = "data/sim_data_fit.RData")
## Load data 
load("data/sim_data_fit.RData")
```


## Model Quality Checks (Simulated Data)
### Markov Chains - Traceplots
```{r}
# ATTENTION WEIGHTS 
#reformat draws data frame to plot trace plots
w_cols <- grep("^w\\[", colnames(draws_df_gcm), value = TRUE)

draws_w_all <- draws_df_gcm %>%
  select(.iteration, .chain, all_of(w_cols)) %>%
  pivot_longer(cols = starts_with("w["), names_to = "param", values_to = "value") %>%
  separate(param, into = c("w", "agent", "feature"), sep = "\\[|,|\\]", convert = TRUE) %>%
  select(-w)
draws_w_all$w_id <- ifelse(draws_w_all$agent %in% seq(1, 10), "even",
                            ifelse(draws_w_all$agent %in% seq(11, 20), "eyes_spots", 
                            ifelse(draws_w_all$agent %in% seq(21, 30), "color_arms", NA)))
draws_w_all$w_id <- as.factor(draws_w_all$w_id)

#Average over agents for each iteration/feature
avg_trace <- draws_w_all %>%
  group_by(.iteration, .chain, w_id, feature) %>%
  summarise(mean_value = mean(value), .groups = "drop")

#Plot traceplots of average attention per feature
ggplot(avg_trace, aes(x = .iteration, y = mean_value,  color = .chain)) +
  geom_line(alpha = 0.6) +
  facet_grid(rows = vars(feature), cols = vars(w_id), 
              labeller = labeller(feature = c(`1` = "Eyes", `2` = "Legs", `3` = "Spots", `4` = "Arms", `5` = "Color")))+
  ggtitle("Traceplots: Average W per Feature and Weight-ID")+
  theme_minimal()
ggsave(filename = "figs/traceplots_average_w.png", width = 10)

# SENSITIVITY PARAMETER (c)
c_cols <- grep("^c\\[", colnames(draws_df_gcm), value = TRUE)

draws_df_gcm %>% 
  select(.iteration, .chain, all_of(c_cols)) %>% 
  pivot_longer(cols = starts_with("c["), names_to = "param", values_to = "value") %>% 
  group_by(.iteration, .chain) %>%
  summarise(mean_value = mean(value), .groups = "drop") %>% 
  ggplot(aes(.iteration, mean_value, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  ggtitle("Traceplot: Average Sentivity Parameter (c)")+
  theme_minimal()
ggsave(filename = "figs/traceplots_average_c.png", width = 10)
```

### Recovery

```{r}
# Reformat Weights for 'recovery' plots
w_summary <- gcm_sum[gcm_sum$variable %in% w_cols,]
w_summary <- w_summary %>% 
  select(c("variable", "mean")) %>% 
  separate(variable, into = c("w", "agent", "feature"), sep = "\\[|,|\\]", convert = TRUE)
w_summary$w_id <- ifelse(w_summary$agent %in% seq(1, 10), "even",
                            ifelse(w_summary$agent %in% seq(11, 20), "eyes_spots", 
                            ifelse(w_summary$agent %in% seq(21, 30), "color_arms", NA)))
w_summary$w_id <- as.factor(w_summary$w_id)

true_w_df <- data.frame(w_id = c(rep("even", 5), rep("eyes_spots", 5), rep("color_arms", 5)),
                        feature = rep(seq(1,5), 3),
                        true_w = c(rep(0.2, 5), softmax(c(1.8, 1, 1.8, 1, 1)), softmax(c(1, 1, 1, 1.8, 1.8))))

w_summary <- left_join(w_summary, true_w_df, by = c("w_id", "feature"))

ggplot(w_summary)+
  geom_point(aes(x = true_w, y = mean))+
  geom_point(aes(y = true_w, x = true_w), colour = "red")+
  lims(x = c(0,0.5), y = c(0,0.5))+
  labs(xlab("est_w"))+
  facet_grid(cols = vars(w_id), rows = vars(feature), 
             labeller = labeller(feature = c(`1` = "Eyes", `2` = "Legs", `3` = "Spots", `4` = "Arms", `5` = "Color")))+
  theme_minimal()
ggsave(filename = "figs/recov_w.png")



```



### Prior-Posterior Update Checks


# FIT & CHECK STAN ON EMPIRICAL DATA

## Fit the STAN Model (Empirical Data)
```{r}

# unique stimuli from empirical data
emp_stim_df <- unique(emp_data[c("dangerous", "eyes", "legs", "spots", "arms", "color")])
emp_stim_df$id <- seq(1:nrow(emp_stim_df))

emp_data <- left_join(emp_data,
                      emp_stim_df, 
                      by = join_by("dangerous", "eyes", "legs", "spots", "arms", "color")) 

# observation matrix
emp_obs <- as.matrix(pivot_wider(emp_data[c("id", "subject", "trial")],
                                 names_from = trial, values_from = id)[-1])

# choice matrix
emp_choice <- as.matrix(pivot_wider(emp_data[c("correct", "subject", "trial")],
                                    names_from = trial, values_from = correct)[-1])

# stimuli feature matrix
emp_stim <- as.matrix(emp_stim_df[c("eyes", "legs", "spots", "arms", "color")])

# create STAN data list
emp_data_ls <- list(
  nagents = length(unique(emp_data$subject)),
  n_trials = max(emp_data$trial), 
  nfeatures = 5,                     
  nstim = nrow(emp_stim_df),                        
  b = 0.5,                        
  stimuli = emp_stim,
  obs = emp_obs,          
  cat_danger = emp_stim_df$dangerous,
  choice = emp_choice,
  w_prior_values = c(1, 1, 1, 1, 1),  # priors for w 
  c_prior_values = c(0, 1))           # priors for c

```

```{r}

emp_file_gcm <- file.path("stan/gcm.stan")
emp_mod_gcm <- cmdstan_model(emp_file_gcm, cpp_options = list(stan_threads = TRUE))

emp_samples_gcm <- emp_mod_gcm$sample(
  data = emp_data_ls,
  seed = 10,
  refresh = 100,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 1,
  iter_warmup = 500,
  iter_sampling = 1000,
  max_treedepth = 20,
  adapt_delta = 0.99)
```

```{r}
emp_gcm_sum <- emp_samples_gcm$summary()
emp_draws_df_gcm <- as_draws_df(emp_samples_gcm$draws())
```

## Save Data
```{r}
# Save emp_gcm_sum and emp_draws_df_gcm as RData
save(emp_gcm_sum, emp_draws_df_gcm, emp_data_ls, file = "data/emp_data_fit.RData")

# Load data 
load("data/emp_data_fit.RData")
```


## Model Quality Checks (Empirical Data)
### Convergence Checks
```{r}

cat("Convergence checks for GSM model on empirical data \n")
gcm_rhat_issues <- emp_gcm_sum %>% 
  filter(rhat > 1.05) %>% 
  nrow()
cat("Empirical GCM model parameters with Rhat > 1.05:", 
    gcm_rhat_issues, "out of", nrow(emp_gcm_sum), "\n")
```

### Markov Chains


```{r}
ggplot(draws_df_simple, aes(.iteration, alpha_prior, group = .chain, color = .chain)) +
  geom_line() +
  ggtitle("Simple Model: Alpha Prior")+
  theme_classic()
ggsave("figs/markov_chains_simple_alpha_prior.png")
```



