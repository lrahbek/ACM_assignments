---
title: "Assignment 4"
output: html_document
date: "2025-05-13"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Load Packages
```{r}
pacman::p_load(tidyverse, here, posterior, cmdstanr, brms, tidybayes, rstan, 
               ggplot2, dplyr, patchwork)
```

# EMPERICAL DATA
## Load Emperical Data and Clean it
Data used contains: 
- *The 'dangerous' category* (not 'nutrisious')
- *Condition 1* dyads (not condition 2)
- *Session 1* danger: aliens with spots AND eyes on stalks (not sessions 2 and 3)
- *Non-test rows* 
```{r}
#emp_data <- read.delim("data/AlienData.txt", sep = ",")
emp_data <- read.delim("AlienData.csv", sep = ",")
emp_data$subject <- as.factor(emp_data$subject)  # make subject categorical
emp_data <- emp_data[emp_data$session == 1 &     # incl only session 1
                       emp_data$condition == 1 & # incl only condition 1
                       emp_data$test == 0,]      # remove test rows
# remove columns not used
emp_data <- emp_data %>% 
  select(-c(condition, session, test, nutricious, RT, motivation, 
            competence, communication, complement)) %>% 
  group_by(subject) %>% 
  mutate(performance = cumsum(correct) / seq_along(correct))
```

## Expand Features
Stimulus column contains the alien-file names. The features are indicated by a 0 or 1 in a set position: 
*1. eyes*: on stalks = 1, not on stalks = 0
*2. legs*: small = 1, big = 0
*3. spots*: spots = 1, no spots = 0
*4. arms*: up = 1, down = 0
*5. color*: green = 1, blue = 0
The five features are added as binary columns
```{r}
emp_data[,c("eyes", "legs", "spots", "arms", "color")] <- str_split_fixed(
  emp_data$stimulus, pattern = "", n = 6)[,1:5]
emp_data <- emp_data %>% 
  mutate_at(c("eyes", "legs", "spots", "arms", "color"), as.integer)
```

## Plot the Emperical Data
### Cumulative Scores and Performance for each Participant 
Calculate mean cumulative value per trial and plot it along each subjects
```{r}
mean_emp <- emp_data %>% 
  group_by(trial) %>% 
  summarise(mean_cum = mean(cumulative)/100, mean_perf = mean(performance))

p1 <- ggplot()+
  geom_line(data = emp_data, aes(group = subject, x = trial, y = cumulative/100), 
            color = "grey")+
  geom_line(data = mean_emp, aes(x = trial, y = mean_cum), color = "purple3")+
  annotate(geom="text", x= nrow(mean_emp)+4, 
           y= mean_emp$mean_cum[mean_emp$trial == nrow(mean_emp)], 
           label="Mean", color = "purple3", size = 3) +
  ggtitle("Emperical Data Cumulative Score")+
  labs(y = "cumulative")+
  theme_minimal()

p2 <- ggplot(emp_data)+
  geom_line(aes(x = trial, y = performance), color = "grey")+
  geom_line(data = mean_emp, aes(x = trial, y = mean_perf), color = "green4")+
  annotate(geom="text", x= nrow(mean_emp)+4, 
           y= mean_emp$mean_perf[mean_emp$trial == nrow(mean_emp)], 
           label="Mean", color = "green4", size = 3) +
  ggtitle("Emperical Data Performance")+
  theme_minimal()
p1/p2
ggsave(filename = "figs/emperical_data_performance.png")
```

### Percentage of Correct Categorisation per Stimuli
```{r}
emp_data_sum <- pivot_wider(
  emp_data[c("stimulus", "correct", "dangerous", "cycle")], 
  names_from = correct, values_from = correct, values_fn = length, values_fill = 0)

colnames(emp_data_sum) <- c("stimuli", "danger", "cycle", "wrong", "correct")
emp_data_sum$stimuli <- str_split_fixed(emp_data_sum$stimuli, 
                                        pattern = ".jpg", n = 2)[,1]
emp_data_sum <- emp_data_sum %>% 
  group_by(cycle) %>% 
  arrange(desc(danger)) %>% 
  group_by(cycle, stimuli) %>% 
  mutate(n = (wrong+correct)) %>% 
  mutate(perc_corr = (correct/n)*100) %>% 
  mutate_at(c("stimuli", "cycle"), as.factor)
```

```{r}
ggplot(emp_data_sum) +
  geom_point(aes(x = cycle, y = stimuli,  size = perc_corr, fill = perc_corr), 
               alpha=0.7, shape = 21, position = position_jitter(width = 0.15)) + 
  scale_fill_viridis_c(breaks = c(25, 50, 75, 100), guide = "legend", name="% Correct")+ 
  scale_size_continuous(range = c(.5, 10),  name="% Correct", 
                        breaks = c(25, 50, 75, 100), guide = "legend")+
  theme_minimal()+ 
  facet_grid(row = "danger", scales = "free_y", space = "free_y", labeller = label_both)+
  theme(panel.grid = element_blank(), 
        panel.spacing = unit(1.5, "lines"))+ 
  coord_cartesian(clip = "off")
```

# FUNCTIONS 
## Experiment Function
The function implements the structure of the experiment, and returns a df with the order of the stimuli for a given number of cycles. It has the following parameters: 
*agent_id*: the id for the given agent
*w_key*: some string indicating what weights are being used. 
*c*: The sensitivity scale used. 
*stimuli*: list of unique stimuli (the 32 alien-filenames)
*cycles*: the number of times the stimuli should be repeated (3 cycles)
*danger_fun*: how the 'danger' category is implemented (so far just the 'ADD' option)
*danger_features*: the features indicating danger
*danger_vals*: the values each of the danger features should have to be dangerous. 

The function returns a dataframe with nrows = number of stimuli * cycles. A stimuli column, a cycle column and a danger column. 
```{r}
experiment <- function(agent_id, w_key, c, stimuli, cycles, danger_fun = "ADD", 
                       danger_features, danger_vals){
  trials <- length(stimuli)*cycles
  n_stim <- length(stimuli)
  stim_df <- data.frame(w = rep(w_key, trials), c = rep(c, trials), 
                        agent_id = rep(agent_id, trials), trial = 1:trials, 
                        cycle = rep(NA, trials), stimuli = rep(NA, trials), 
                        danger = rep(NA, trials))
  for(cycle in 1:cycles){
    stim_order <- sample(stimuli, size = n_stim, replace = F)
    for(i in 1:n_stim){
      n_trial <- i+((cycle-1) *n_stim)
      stim_df[n_trial, "cycle"] <- cycle
      stim_df[n_trial , "stimuli"] <- stim_order[i]
    }
  } 
  stim_df[,c("eyes", "legs", "spots", "arms", "color")] <- str_split_fixed(
    stim_df$stimuli, pattern = "", n = 5)
  if(danger_fun == "ADD"){
    stim_df$danger <- ifelse(stim_df[danger_features[1]] == danger_vals[1] & 
                             stim_df[danger_features[2]] == danger_vals[2], 1, 0)[,1]
  }
  else{
    print("The danger function is not implemented in the experiment function")
  }
  stim_df <- stim_df %>% mutate_at(c("danger", "eyes", "legs", "spots", "arms", "color"), as.integer)
  return(stim_df)
}
```

## Softmax Function
Softmax function to generate weights for the features that sum to 1 
```{r}
softmax <- function(vector){
  return(exp(vector)/sum(exp(vector)))
}
```

## General Context Model Functions
### Distance & Similarity
```{r}
distance <- function(vect1, vect2, w) {
  return(sum(w * abs(vect1 - vect2)))
}

similarity <- function(distance, c) {
  return(exp(-c * distance))
}
```

### Agent Functions 
- *w*       : Attention weight (attention to parameter dimensions, sums to 1)
- *c*       : Sensitivity parameter (determines how quickly similarity decreases with distance)
- *obs*     : Obervations (list of simuli, one for each trial)
- *cat_list*: List of 0/1 for each trial (1 = danger, 0 = not danger) 
```{r}
gcm_agent <- function(w, c, obs, cat_list){
  cat_probs <- c()     # list of probabilities of selecting '1' (danger) for each trial
  ntrials <- nrow(obs) # number of trials
  for (i in 1:ntrials){
    # for first trial and if the category hasn't been seen yet: 
    if (i == 1 || sum(cat_list[1:(i - 1)]) == 0 || sum(cat_list[1:(i - 1)]) == (i - 1)) {
      cat_probs <- c(cat_probs, 0.5) # random guess 
    }
    else {
      similarities <- c() # list of similarities between current simuli and all previous
      for (e in 1:(i - 1)) {
        dist <- distance(obs[i, ], obs[e, ], w)              # calculate distance
        similarities <- c(similarities, similarity(dist, c)) # caluclate similarity
      }
      # probability of categorising i as dangerous: 
      numerator <- mean(similarities[cat_list[1:(i - 1)] == 1])
      denominator <- mean(similarities[cat_list[1:(i - 1)] == 1]) + mean(
        similarities[cat_list[1:(i - 1)] == 0])
      cat_probs <- c(cat_probs, numerator / denominator)
    }
  }
  choices <- rbinom(ntrials, 1, cat_probs)
  return(choices)
}
```

# SIMULATION
## Simulate Agents
```{r}
#different weight dists
weights <- list("even" = softmax(rep(1, 5)),                 # 0.2 0.2 0.2 0.2 0.2
                "eyes_spots" = softmax(c(1.8, 1, 1.8, 1, 1)),# 0.299 0.134 0.299 0.134 0.134
                "color_arms" = softmax(c(1, 1, 1, 1.8, 1.8)))# 0.134 0.134 0.134 0.299 0.299
c <- 1.5                # sensitivity paramater 
cycles <- 3             # number of times stimuli is repeated

n_agents <- 10*length(weights)  # number of agents to be simulated: 10 with each of the weight dists 

# define unique stimuli: 
stim <- unique(str_split_fixed(emp_data$stimulus, pattern = ".jpg", n = 2)[,1]) 
d_features <- c("eyes", "spots") #the features that with d_vals indicate danger
d_vals <- c(1, 1)                #the values of d_features for them to indicate danger


for (j in 1:length(weights)){
  w <- weights[[j]] # vector of weights for each feature
  for(i in (j*10-9):(j*10)){ #go through ten agents for each weight vect (1: 1-10, 2: 11-20, 3: 21-30)
    # create exp data frame and unique stim order for given agent: 
    exp_df <- experiment(agent_id = i, w = names(weights)[j], c = c, 
                         stimuli = stim , cycles = cycles, danger_fun = "ADD",
                         danger_features = d_features, danger_vals = d_vals)
    # generate choices for the agent according to GCM: 
    exp_df$a_choices <- gcm_agent(
      w = w, c = c, obs = exp_df[c("eyes", "legs", "spots", "arms", "color")], 
      cat_list = exp_df$danger)
    # Define correct choices, cumulative scores and performance: 
    exp_df$correct <- ifelse(exp_df$a_choices == exp_df$danger, 1, 0) 
    exp_df$cumulative <- cumsum(ifelse(exp_df$correct == 1, 1, -1))   
    exp_df$performance <- cumsum(exp_df$correct) / seq_along(exp_df$correct)
    if (i == 1){
      sim_data <- exp_df
    }
    else{
      sim_data <- rbind(sim_data, exp_df)
    }
  }
  if (j == 1){
    sim_data_w <- sim_data
  }
  else{
    sim_data_w <- rbind(sim_data_w, sim_data)
  }
  cat("Finished simulating", n_agents, "agents with w of", w, "\n")
}
```

## Plot Performance and Cumulative Score of Simulation
```{r}
mean_sim <- sim_data_w %>% 
  group_by(w, trial) %>%   
  summarise(mean_cum = mean(cumulative), mean_perf = mean(performance))

ggplot()+
  geom_line(data = sim_data_w, aes(x = trial, y = cumulative),color = "grey")+
  geom_line(data = mean_sim, aes(x = trial, y = mean_cum, color = w), show.legend = F)+
  scale_color_viridis_d()+
  ggtitle("Simulation Cumulative Score (c: 1)")+
  facet_wrap(~w, labeller = label_both)+
  theme_minimal()
ggsave(filename = "figs/sim_cumulative.png")

ggplot()+
  geom_line(data = sim_data_w, aes(x = trial, y = performance), color = "grey")+
  geom_line(data = mean_sim, aes(x = trial, y = mean_perf, color = w), show.legend = F)+
  scale_color_viridis_d()+
  ggtitle("Simulation Performance (c: 1)")+
  facet_wrap(~w, labeller = label_both)+
  theme_minimal()
ggsave(filename = "figs/sim_performance.png")
```

## Percentage of Correct Categorisation per Stimuli Plot 
```{r}
## calculate percent correct categorisations
sim_data_sum <- pivot_wider(sim_data_w[c("w", "stimuli", "correct", "danger", "cycle")], 
                            names_from = correct, values_from = correct, values_fn = length, 
                            values_fill = 0)
colnames(sim_data_sum) <- c("w", "stimuli", "danger", "cycle", "wrong", "correct")
sim_data_sum <- sim_data_sum %>% 
  group_by(w, cycle, stimuli) %>% 
  mutate(perc_corr = (correct/(wrong+correct))*100) %>% 
  mutate_at( "cycle", as.factor)
```

```{r}
ggplot(sim_data_sum) +
  geom_point(aes(x = cycle, y = stimuli,  size = perc_corr, fill = perc_corr), 
               alpha=0.7, shape = 21, position = position_jitter(width = 0.25)) + 
  scale_fill_viridis_c(breaks = c(30, 50, 70, 90), guide = "legend", name="% Correct")+ 
  scale_size_continuous(range = c(.1, 8),  name="% Correct", 
                        breaks = c(30, 50, 70, 90), guide = "legend")+
  theme_minimal()+ 
  facet_grid(row = vars(danger), col = vars(w), scales = "free_y", 
             space = "free_y", labeller = label_both)+
  theme(panel.grid = element_blank(), 
        panel.spacing = unit(1.5, "lines"))+ 
  coord_cartesian(clip = "off")
```



## Save in STAN-friendly Format
```{r}
# unique stimuli and category df with stimuli ids : 
stim_df <- unique(sim_data_w[c("danger", "eyes", "legs", "spots", "arms", "color")])
stim_df$s_id <- seq(1:nrow(stim_df))
#combine stim_df with ids and simulated df 
sim_data_w <- left_join(sim_data_w, stim_df)

sim_data <- list(
  total_N = nrow(sim_data_w),                    # total number of observations (all agents)
  nagents = length(unique(sim_data_w$agent_id)), # number of individual agents
  agent_id = sim_data_w$agent_id,                # agent id for each observation
  n_trials = 96,                                 # number of trials for each agent 
  nfeatures = 5,                                 # number of features for stimuli
  nstim = 32,                                    # number of unique stimuli
  stimuli = as.matrix(stim_df[c(
  "eyes", "legs", "spots", "arms", "color")]),   # matrix of [nstim, nfeatures] indices: s_id
  cat_danger = stim_df$danger,                   # array of cats with indices as s_id
  obs = sim_data_w$s_id,                         # array of stim id of length total_N
  b = 0.5,                                       # bias for selecting one cat over the other
  choice = sim_data_w$a_choices                  # array of choice for each trial 
)

```


# STAN MODEL
Build a simple * difficulty dimensional model
If the alien has eyes AND spots = true danger.
Added other rules in case we want to make it more complicated
*1. eyes*: on stalks = 1, not on stalks = 0
*2. legs*: small = 1, big = 0
*3. spots*: spots = 1, no spots = 0
*4. arms*: up = 1, down = 0
*5. color*: green = 1, blue = 0
```{r}
# Use all simulated data (e.g., from sim_data_w)
stan_sim_data <- list(
  ntrials = nrow(sim_data_w),
  nfeatures = 5,
  y = sim_data_w$danger,
  obs = as.matrix(sim_data_w[, c("eyes", "legs", "spots", "arms", "color")])
)


stan_code <- '
data {
  int<lower=1> ntrials;
  int<lower=1> nfeatures; // should be 5
  array[ntrials] int<lower=0, upper=1> y; // observed response (1 = "dangerous")
  array[ntrials, nfeatures] int<lower=0, upper=1> obs; // feature matrix
}

parameters {
  real<lower=0.001, upper=0.999> error_prob;
}

model {
  error_prob ~ beta(1.1, 10); // prior favoring lower error

  for (i in 1:ntrials) {
    vector[4] log_prob_rules;

    // Rule 1: eyes AND spots = DANGER
    int pred1 = (obs[i, 1] == 1 && obs[i, 3] == 1) ? 1 : 0;
    log_prob_rules[1] = bernoulli_lpmf(y[i] | pred1 == 1 ? 1 - error_prob : error_prob);

    // Rule 2: arms up = SAFE
    int pred2 = (obs[i, 4] == 1) ? 1 : 0;
    log_prob_rules[2] = bernoulli_lpmf(y[i] | pred2 == 0 ? 1 - error_prob : error_prob);

    // Rule 3: eyes OR color = SAFE
    int pred3 = (obs[i, 1] == 1 || obs[i, 5] == 1) ? 1 : 0;
    log_prob_rules[3] = bernoulli_lpmf(y[i] | pred3 == 0 ? 1 - error_prob : error_prob);

    // Rule 4: legs AND color = SAFE
    int pred4 = (obs[i, 2] == 1 && obs[i, 5] == 1) ? 1 : 0;
    log_prob_rules[4] = bernoulli_lpmf(y[i] | pred4 == 0 ? 1 - error_prob : error_prob);

    // Average across rules
    target += log_sum_exp(log_prob_rules) - log(4);
  }
}

generated quantities {
  array[ntrials] real log_lik;
  for (i in 1:ntrials) {
    vector[4] log_prob_rules;

    // Rule 1: eyes AND spots = DANGER
    int pred1 = (obs[i, 1] == 1 && obs[i, 3] == 1) ? 1 : 0;
    log_prob_rules[1] = bernoulli_lpmf(y[i] | pred1 == 1 ? 1 - error_prob : error_prob);

    // Rule 2: arms up = SAFE
    int pred2 = (obs[i, 4] == 1) ? 1 : 0;
    log_prob_rules[2] = bernoulli_lpmf(y[i] | pred2 == 0 ? 1 - error_prob : error_prob);

    // Rule 3: eyes OR color = SAFE
    int pred3 = (obs[i, 1] == 1 || obs[i, 5] == 1) ? 1 : 0;
    log_prob_rules[3] = bernoulli_lpmf(y[i] | pred3 == 0 ? 1 - error_prob : error_prob);

    // Rule 4: legs AND color = SAFE
    int pred4 = (obs[i, 2] == 1 && obs[i, 5] == 1) ? 1 : 0;
    log_prob_rules[4] = bernoulli_lpmf(y[i] | pred4 == 0 ? 1 - error_prob : error_prob);

    log_lik[i] = log_sum_exp(log_prob_rules) - log(4);
  }
}

'

writeLines(stan_code, "models/danger_rule_model.stan")
```


# FIT & CHECK STAN ON SIMULATED DATA 

## Fit the STAN Model (Simulated Data)
```{r}
model <- cmdstan_model("models/danger_rule_model.stan")
fit_sim <- model$sample(
  data = stan_sim_data,
  chains = 4,
  iter_warmup = 500,
  iter_sampling = 1000,
  seed = 42
)
```

## Model Quality Checks (Simulated Data)
```{r}
# Print basic summary
print(fit_sim)

# Check convergence diagnostics
posterior::rhat(fit_sim$draws())                      # R-hat values (should be ≈ 1)
fit_sim$cmdstan_diagnose()                            # CmdStan diagnostic checks

# Summarize posterior for error_prob
posterior::summarise_draws(fit_sim$draws("error_prob"))

# Extract draws and plot posterior distribution
draws_df <- posterior::as_draws_df(fit_sim$draws("error_prob"))

ggplot(draws_df, aes(x = error_prob)) +
  geom_density(fill = "lightblue", alpha = 0.7) +
  ggtitle("Posterior of Error Probability (Simulated Data)") +
  xlab("Error Probability") +
  theme_minimal()

 ggsave("figs/sim_error_prob.png")
```


# FIT & CHECK STAN ON EMPERICAL DATA

## Fit the STAN Model (Emperical Data)
```{r}
emp_sub <- emp_data #%>% filter(subject == 1)  #choose a specific subject

stan_emp_data <- list(
  ntrials = nrow(emp_sub),
  nfeatures = 5,
  y = emp_sub$dangerous,
  obs = as.matrix(emp_sub[, c("eyes", "legs", "spots", "arms", "color")])
)

fit_emp <- model$sample(
  data = stan_emp_data,
  chains = 4,
  iter_warmup = 500,
  iter_sampling = 1000,
  seed = 101
)
```

## Model Quality Checks (Emperical Data)
```{r}
# Print basic summary
print(fit_emp)

# Check convergence diagnostics
posterior::rhat(fit_emp$draws())                      # R-hat values (should be ≈ 1)
fit_emp$cmdstan_diagnose()                            # CmdStan diagnostic checks

# Summarize posterior for error_prob
posterior::summarise_draws(fit_emp$draws("error_prob"))

# Extract draws and plot posterior distribution
draws_df_emp <- posterior::as_draws_df(fit_emp$draws("error_prob"))

ggplot(draws_df_emp, aes(x = error_prob)) +
  geom_density(fill = "lightpink", alpha = 0.7) +
  ggtitle("Posterior of Error Probability (Empirical Data)") +
  xlab("Error Probability") +
  theme_minimal()

ggsave(filename = "figs/emp_error.png")
```







